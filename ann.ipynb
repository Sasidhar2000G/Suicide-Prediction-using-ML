{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd06b9b909b0db89dc5154d04f41023f27d2e61b57177831d3d7dfaaa053ee06c5a",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "6b9b909b0db89dc5154d04f41023f27d2e61b57177831d3d7dfaaa053ee06c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1+(np.exp(-x))))\n",
    "def sigmoid_derivative(x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random starting synaptic weights: \n[[-0.16595599]\n [ 0.44064899]]\n"
     ]
    }
   ],
   "source": [
    "trainarr = []\n",
    "temp2=[]\n",
    "trainoparr = []\n",
    "csv_reader = csv.DictReader(open('ann.csv'))\n",
    "for line in csv_reader:\n",
    "    temp = []\n",
    "    temp.append(float(line['sid']))\n",
    "    temp.append(float(line['sentiment']))\n",
    "    trainarr.append(temp)\n",
    "    temp2.append(int(line['target']))\n",
    "trainoparr.append(temp2)\n",
    "training_inputs = np.array(trainarr)\n",
    "training_outputs = np.array(trainoparr).T\n",
    "np.random.seed(1)\n",
    "\n",
    "synaptic_weights = 2 * np.random.random((2,1)) - 1\n",
    "\n",
    "print('Random starting synaptic weights: ')\n",
    "print(synaptic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ouputs after training : \n[[9.99999921e-01]\n [1.00000000e+00]\n [1.00000000e+00]\n [9.95451673e-01]\n [1.00000000e+00]\n [9.99999995e-01]\n [9.99993433e-01]\n [9.99998216e-01]\n [9.99999990e-01]\n [9.99985383e-01]\n [9.99273347e-01]\n [1.00000000e+00]\n [9.92262333e-01]\n [1.00000000e+00]\n [1.00000000e+00]\n [1.00000000e+00]\n [9.99999993e-01]\n [9.99999624e-01]\n [9.99952456e-01]\n [5.09077389e-02]\n [8.42095017e-01]\n [9.99644466e-01]\n [1.00000000e+00]\n [9.99999917e-01]\n [3.89525206e-01]\n [1.00000000e+00]\n [1.00000000e+00]\n [9.99999999e-01]\n [1.00000000e+00]\n [1.00000000e+00]\n [1.00000000e+00]\n [1.00000000e+00]\n [1.00000000e+00]\n [7.67157305e-01]\n [9.99971656e-01]\n [9.82123789e-01]\n [9.99999994e-01]\n [6.59796044e-01]\n [9.99999888e-01]\n [9.96479881e-01]\n [9.99999717e-01]\n [9.99993307e-01]\n [1.00000000e+00]\n [1.00000000e+00]\n [5.74451751e-01]\n [1.00000000e+00]\n [9.60725229e-01]\n [9.99999379e-01]\n [9.99999668e-01]\n [9.99205365e-01]\n [1.39057878e-04]\n [2.14956063e-05]\n [4.61050447e-05]\n [1.73571619e-01]\n [2.14750955e-04]\n [6.92718263e-06]\n [6.99306657e-06]\n [4.32480007e-09]\n [2.45519845e-07]\n [1.25561462e-07]\n [5.53439026e-09]\n [2.47234693e-06]\n [9.35547340e-07]\n [6.04123184e-02]\n [6.69674068e-09]\n [3.26412906e-05]\n [1.65253572e-08]\n [8.15110395e-07]\n [4.32798986e-06]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(2000):\n",
    "    input_layer = training_inputs\n",
    "    outputs = sigmoid(np.dot(input_layer,synaptic_weights))\n",
    "    error = training_outputs - outputs\n",
    "    adjustements = error * sigmoid_derivative(outputs)       \n",
    "    synaptic_weights += np.dot(input_layer.T,adjustements)\n",
    "\n",
    "print('Ouputs after training : ')\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Synaptic weights after Training\n[[31.12882403]\n [ 6.0397378 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Synaptic weights after Training')\n",
    "print(synaptic_weights)"
   ]
  },
  {
   "source": [
    "Our Training is Over now it's time for prediction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2.08849182e-05]]\n"
     ]
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "text = \"Luckily I donâ€™t have to pay you for making me happy. I would have been bankrupt already if I had to!\"\n",
    "obj = TextBlob(text)\n",
    "sentiment = obj.sentiment.polarity\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "text_list = tokenizer.tokenize(text)\n",
    "csv_reader = csv.DictReader(open('trainds.csv','r'))\n",
    "sid = 0\n",
    "for line in csv_reader:\n",
    "    for text in text_list:\n",
    "        if(line['words']==text):\n",
    "            sid+=float(line['weights'])\n",
    "temp = []\n",
    "temp.append(sid)\n",
    "temp.append(sentiment)\n",
    "iarr = []\n",
    "iarr.append(temp)\n",
    "test_input = np.array(iarr)\n",
    "test_output = sigmoid(np.dot(test_input,synaptic_weights))\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The probability of the person having Sucidal Ideation is 0% .\n"
     ]
    }
   ],
   "source": [
    "prob = int(test_output*100)\n",
    "print(\"The probability of the person having Sucidal Ideation is \"+str(prob)+\"% .\")"
   ]
  }
 ]
}