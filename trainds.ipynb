{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd06b9b909b0db89dc5154d04f41023f27d2e61b57177831d3d7dfaaa053ee06c5a",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "6b9b909b0db89dc5154d04f41023f27d2e61b57177831d3d7dfaaa053ee06c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Luckily -0.022727272727272728\nI -0.024994620205127757\ndon√¢ -0.022727272727272728\nt -0.023835903121166367\nhave -0.025187713497925278\nto -0.02493910030819304\npay -0.022727272727272728\nyou -0.024375161977154614\nfor -0.024479246096145\nmaking -0.024509379509379512\nme -0.024326734209124155\nhappy -0.024329157507312512\nI -0.024994620205127757\nwould -0.020159096977287325\nhave -0.025187713497925278\nbeen -0.02439117246638055\nbankrupt -0.022727272727272728\nalready -0.022727272727272728\nif -0.023213439264678826\nI -0.024994620205127757\nhad -0.023666987369061535\nto -0.02493910030819304\n"
     ]
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "with open('sample.csv','r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for line in csv_reader:\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        text_list = tokenizer.tokenize(line['notes'])\n",
    "        for text in text_list:\n",
    "            for word in text.split():\n",
    "                if(int(line['target']) == 1):\n",
    "                    word_freq[word] += 1\n",
    "                else:\n",
    "                    word_freq[word] -= 0.25\n",
    "            weight = word_freq[word]/len(text_list)\n",
    "            weight +=weight\n",
    "            word_freq[word] = weight  "
   ]
  },
  {
   "source": [
    "\n",
    "with open('trainds.csv','w') as new_file:\n",
    "    \n",
    "    header = ['words','weights']\n",
    "    csv_writer = csv.writer(new_file)\n",
    "    csv_writer.writerow(header)\n",
    "    for word in word_freq:\n",
    "        csv_writer.writerow([word,word_freq[word]])\n",
    "        "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5544152956760428 -0.15000000000000002 1\n",
      "1.64944391662961 0.033333333333333326 1\n",
      "0.7193203850649365 -0.09666666666666668 1\n",
      "0.1731291044485606 0.0 1\n",
      "1.4167015221742874 -0.10285714285714284 1\n",
      "0.6144168137912134 0.0 1\n",
      "0.3834170175667228 0.0 1\n",
      "0.4085902654683854 0.08611111111111111 1\n",
      "0.5909402459545972 0.0 1\n",
      "0.3395203590830874 0.09375 1\n",
      "0.23218027909798694 0.0 1\n",
      "0.7892747154120144 0.4000000000000001 1\n",
      "0.1559541589863991 0.0 1\n",
      "1.4900616978273362 0.11666666666666665 1\n",
      "0.9354548778567501 0.0 1\n",
      "1.2080649206892886 0.25 1\n",
      "0.601675281226988 0.0 1\n",
      "0.4752914187395343 0.0 1\n",
      "0.31981333304156806 0.0 1\n",
      "-0.19100391004621706 0.5 0\n",
      "0.11037032654221408 -0.2916666666666667 1\n",
      "0.28345361920534806 -0.14583333333333334 1\n",
      "1.3180051896228169 0.0 1\n",
      "0.4755084960461642 0.25 1\n",
      "-0.014436164853368209 0.0 1\n",
      "0.7816602925459986 -0.041666666666666664 1\n",
      "0.7544401756684362 0.0 1\n",
      "0.6689121434418179 0.0 1\n",
      "1.2584353757007039 0.125 1\n",
      "1.1076728990401872 0.0 1\n",
      "0.8209912616284378 0.0 1\n",
      "0.6758588621616609 0.12499999999999999 1\n",
      "0.9336927517016176 -0.09444444444444444 1\n",
      "0.038309218428431005 0.0 1\n",
      "0.3301372417432633 0.03244949494949494 1\n",
      "0.03171104547409414 0.5 1\n",
      "0.560944023687331 0.25 1\n",
      "-0.05493879193064957 0.39285714285714285 1\n",
      "0.5810784065188876 -0.3444444444444444 1\n",
      "0.1364717567361435 0.23154761904761909 1\n",
      "0.4843919721676779 0.0 1\n",
      "0.44343774970296845 -0.3125 1\n",
      "0.8544986708348524 0.0 1\n",
      "0.8536634970481097 0.0 1\n",
      "0.009640136963827914 0.0 1\n",
      "0.6599962870105758 0.175 1\n",
      "-0.03308988251521643 0.7 1\n",
      "0.4327791041362331 0.1361111111111111 1\n",
      "0.4793019744429046 0.0 1\n",
      "0.20828606380800918 0.10833333333333334 1\n",
      "-0.40173794743125935 0.6 0\n",
      "-0.4229258440485274 0.4 0\n",
      "-0.41573065662541353 0.4892857142857143 0\n",
      "-0.20535301263244912 0.8 0\n",
      "-0.38130504693219597 0.5666666666666668 0\n",
      "-0.49423299282225974 0.5800000000000001 0\n",
      "-0.5075100593633985 0.65 0\n",
      "-0.6260591738209527 0.037500000000000026 0\n",
      "-0.5278145532966593 0.2 0\n",
      "-0.5804029601491492 0.36 0\n",
      "-0.6788582647597431 0.35047619047619044 0\n",
      "-0.5591062659346652 0.74375 0\n",
      "-0.5619546999343619 0.5974999999999999 0\n",
      "-0.24338579899327561 0.8 0\n",
      "-0.6920424019565519 0.45 0\n",
      "-0.4806436062130325 0.7666666666666666 0\n",
      "-0.5886471214723662 0.0666666666666667 0\n",
      "-0.5571666257832124 0.5499999999999999 0\n",
      "-0.5261601303616739 0.6666666666666666 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_writer1 = csv.writer(open('ann.csv','w'))\n",
    "csv_writer1.writerow(['sid','sentiment','target'])\n",
    "csv_reader1 = csv.DictReader(open('sample.csv','r'))\n",
    "for notes in csv_reader1:\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text_list = tokenizer.tokenize(notes['notes'])\n",
    "    obj = TextBlob(notes['notes'])\n",
    "    sentiment = obj.sentiment.polarity\n",
    "    csv_reader = csv.DictReader(open('trainds.csv','r'))\n",
    "    sid = 0\n",
    "    target = notes['target']\n",
    "    for line in csv_reader:\n",
    "        for text in text_list:\n",
    "            if(line['words']==text):\n",
    "                sid+=float(line['weights'])\n",
    "    print(sid,sentiment,target)\n",
    "    csv_writer1.writerow([sid,sentiment,target])"
   ]
  }
 ]
}